#!/usr/bin/env node
/**
 * Azure Speech STT æµ‹è¯•è„šæœ¬
 *
 * ç”¨æ³•:
 *   node scripts/test-azure-stt.js                     # ç”¨é™éŸ³ WAV æµ‹è¯• API è¿é€šæ€§
 *   node scripts/test-azure-stt.js path/to/audio.amr   # è½¬å½• AMR æ–‡ä»¶ï¼ˆéœ€è¦ ffmpegï¼‰
 *   node scripts/test-azure-stt.js path/to/audio.wav   # ç›´æ¥è½¬å½• WAV æ–‡ä»¶
 *   node scripts/test-azure-stt.js path/to/audio.mp3   # è½¬å½• MP3 æ–‡ä»¶ï¼ˆéœ€è¦ ffmpegï¼‰
 *
 * ç¯å¢ƒå˜é‡ (ä»é¡¹ç›®æ ¹ç›®å½• .env æ–‡ä»¶è¯»å–):
 *   AZURE_SPEECH_KEY    - Azure Speech å¯†é’¥
 *   AZURE_SPEECH_REGION - Azure Speech åŒºåŸŸ (å¦‚ eastasia)
 *   AZURE_SPEECH_LANG   - è¯†åˆ«è¯­è¨€ (é»˜è®¤ zh-CN)
 */

import { readFile, writeFile, unlink } from "node:fs/promises";
import { existsSync } from "node:fs";
import { execFile } from "node:child_process";
import { promisify } from "node:util";
import { tmpdir } from "node:os";
import { join, extname } from "node:path";
import { fileURLToPath } from "node:url";
import { dirname } from "node:path";

const execFileAsync = promisify(execFile);
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const projectRoot = join(__dirname, "..");

// ============================================================================
// åŠ è½½ .env
// ============================================================================
async function loadEnv() {
    const envPath = join(projectRoot, ".env");
    if (!existsSync(envPath)) {
        console.error("âŒ æœªæ‰¾åˆ° .env æ–‡ä»¶");
        console.error("   è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å†™ Azure Speech å¯†é’¥:");
        console.error("   cp .env.example .env");
        process.exit(1);
    }

    const content = await readFile(envPath, "utf-8");
    for (const line of content.split("\n")) {
        const trimmed = line.trim();
        if (!trimmed || trimmed.startsWith("#")) continue;
        const eqIdx = trimmed.indexOf("=");
        if (eqIdx > 0) {
            const key = trimmed.slice(0, eqIdx).trim();
            const value = trimmed.slice(eqIdx + 1).trim();
            if (!process.env[key]) {
                process.env[key] = value;
            }
        }
    }
}

// ============================================================================
// ç”Ÿæˆé™éŸ³ WAV (ç”¨äºæµ‹è¯• API è¿é€šæ€§)
// ============================================================================
function createSilentWav(durationSeconds = 1, sampleRate = 16000) {
    const numChannels = 1;
    const bitsPerSample = 16;
    const bytesPerSample = bitsPerSample / 8;
    const numSamples = sampleRate * durationSeconds;
    const dataSize = numSamples * numChannels * bytesPerSample;
    const headerSize = 44;
    const buffer = Buffer.alloc(headerSize + dataSize);

    // RIFF header
    buffer.write("RIFF", 0);
    buffer.writeUInt32LE(36 + dataSize, 4);
    buffer.write("WAVE", 8);

    // fmt chunk
    buffer.write("fmt ", 12);
    buffer.writeUInt32LE(16, 16);
    buffer.writeUInt16LE(1, 20);                                    // PCM
    buffer.writeUInt16LE(numChannels, 22);
    buffer.writeUInt32LE(sampleRate, 24);
    buffer.writeUInt32LE(sampleRate * numChannels * bytesPerSample, 28);
    buffer.writeUInt16LE(numChannels * bytesPerSample, 32);
    buffer.writeUInt16LE(bitsPerSample, 34);

    // data chunk
    buffer.write("data", 36);
    buffer.writeUInt32LE(dataSize, 40);
    // æ•°æ®å…¨ä¸º 0 (é™éŸ³) â€” Buffer.alloc å·²åˆå§‹åŒ–

    return buffer;
}

// ============================================================================
// éŸ³é¢‘è½¬ WAV (é€šè¿‡ ffmpeg)
// ============================================================================
async function convertToWav(inputPath) {
    const ext = extname(inputPath).toLowerCase();

    // WAV æ–‡ä»¶ç›´æ¥è¯»å–ï¼ˆä¸éœ€è¦ ffmpegï¼‰
    if (ext === ".wav") {
        console.log("ğŸ“„ WAV æ–‡ä»¶ï¼Œç›´æ¥è¯»å–...");
        return await readFile(inputPath);
    }

    // é WAV æ–‡ä»¶éœ€è¦ ffmpeg è½¬æ¢
    console.log(`ğŸ”„ è½¬æ¢ ${ext} â†’ WAV (é€šè¿‡ ffmpeg)...`);
    const tmpOut = join(tmpdir(), `stt_test_${Date.now()}.wav`);
    try {
        await execFileAsync("ffmpeg", [
            "-y", "-i", inputPath,
            "-f", "wav", "-ar", "16000", "-ac", "1", "-acodec", "pcm_s16le",
            tmpOut,
        ], { timeout: 30000 });
        const buf = await readFile(tmpOut);
        console.log(`âœ… è½¬æ¢å®Œæˆ: ${buf.length} bytes`);
        return buf;
    } catch (err) {
        if (err.code === "ENOENT") {
            console.error("âŒ ffmpeg æœªå®‰è£…ã€‚é WAV æ ¼å¼æ–‡ä»¶éœ€è¦ ffmpeg è½¬æ¢:");
            console.error("   Linux:  apt install ffmpeg");
            console.error("   macOS:  brew install ffmpeg");
            console.error("   Windows: winget install ffmpeg");
            process.exit(1);
        }
        throw err;
    } finally {
        await unlink(tmpOut).catch(() => {});
    }
}

// ============================================================================
// è°ƒç”¨ Azure STT
// ============================================================================
async function callAzureStt(wavBuffer, config) {
    const { key, region, lang } = config;

    const url = `https://${region}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=${lang}&format=detailed`;

    console.log(`ğŸ™ï¸ è°ƒç”¨ Azure STT...`);
    console.log(`   åŒºåŸŸ: ${region}`);
    console.log(`   è¯­è¨€: ${lang}`);
    console.log(`   éŸ³é¢‘å¤§å°: ${wavBuffer.length} bytes`);

    const startTime = Date.now();

    const response = await fetch(url, {
        method: "POST",
        headers: {
            "Ocp-Apim-Subscription-Key": key,
            "Content-Type": "audio/wav; codecs=audio/pcm; samplerate=16000",
            "Accept": "application/json",
        },
        body: wavBuffer,
        signal: AbortSignal.timeout(30000),
    });

    const elapsed = Date.now() - startTime;

    if (!response.ok) {
        const errorText = await response.text().catch(() => "");
        console.error(`âŒ Azure STT è¿”å› HTTP ${response.status}`);
        console.error(`   å“åº”: ${errorText.substring(0, 500)}`);
        process.exit(1);
    }

    const data = await response.json();
    console.log(`â±ï¸ è€—æ—¶: ${elapsed}ms`);

    return data;
}

// ============================================================================
// ä¸»æµç¨‹
// ============================================================================
async function main() {
    await loadEnv();

    const key = process.env.AZURE_SPEECH_KEY;
    const region = process.env.AZURE_SPEECH_REGION || "eastasia";
    const lang = process.env.AZURE_SPEECH_LANG || "zh-CN";

    if (!key) {
        console.error("âŒ ç¼ºå°‘ AZURE_SPEECH_KEY ç¯å¢ƒå˜é‡");
        console.error("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® AZURE_SPEECH_KEY");
        process.exit(1);
    }

    console.log("========================================");
    console.log("  Azure Speech STT æµ‹è¯•");
    console.log("========================================\n");

    const audioFile = process.argv[2];
    let wavBuffer;

    if (audioFile) {
        // ä½¿ç”¨ç”¨æˆ·æä¾›çš„éŸ³é¢‘æ–‡ä»¶
        if (!existsSync(audioFile)) {
            console.error(`âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${audioFile}`);
            process.exit(1);
        }

        const ext = extname(audioFile).toLowerCase();
        console.log(`ğŸ“ è¾“å…¥æ–‡ä»¶: ${audioFile} (${ext})`);

        if (ext === ".wav") {
            // å¯èƒ½éœ€è¦é‡é‡‡æ ·
            wavBuffer = await convertToWav(audioFile);
        } else {
            // éœ€è¦ ffmpeg è½¬æ¢
            wavBuffer = await convertToWav(audioFile);
        }
    } else {
        // æ²¡æœ‰æä¾›æ–‡ä»¶ï¼Œä½¿ç”¨é™éŸ³ WAV æµ‹è¯•è¿é€šæ€§
        console.log("ğŸ“ æœªæŒ‡å®šéŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨ 1 ç§’é™éŸ³æµ‹è¯• API è¿é€šæ€§...");
        console.log("   (æç¤º: ä¼ å…¥éŸ³é¢‘æ–‡ä»¶æµ‹è¯•å®é™…è½¬å½•æ•ˆæœ)");
        console.log(`   ç”¨æ³•: node scripts/test-azure-stt.js <éŸ³é¢‘æ–‡ä»¶è·¯å¾„>\n`);
        wavBuffer = createSilentWav(1);
    }

    // è°ƒç”¨ Azure STT
    const result = await callAzureStt(wavBuffer, { key, region, lang });

    // è¾“å‡ºç»“æœ
    console.log("\n========== è¯†åˆ«ç»“æœ ==========");
    console.log(`çŠ¶æ€: ${result.RecognitionStatus}`);

    if (result.RecognitionStatus === "Success") {
        console.log(`âœ… è¯†åˆ«æ–‡æœ¬: ${result.DisplayText}`);
        if (result.NBest && result.NBest.length > 0) {
            console.log(`   ç½®ä¿¡åº¦: ${(result.NBest[0].Confidence * 100).toFixed(1)}%`);
            if (result.NBest.length > 1) {
                console.log("   å€™é€‰é¡¹:");
                result.NBest.forEach((item, i) => {
                    console.log(`     ${i + 1}. [${(item.Confidence * 100).toFixed(1)}%] ${item.Display}`);
                });
            }
        }
    } else if (result.RecognitionStatus === "NoMatch" || result.RecognitionStatus === "InitialSilenceTimeout") {
        if (audioFile) {
            console.log("âš ï¸ æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹");
        } else {
            console.log("âœ… API è¿é€šæ€§æ­£å¸¸ï¼ï¼ˆé™éŸ³æµ‹è¯•é¢„æœŸè¿”å› NoMatchï¼‰");
        }
    } else {
        console.log(`âš ï¸ éé¢„æœŸçŠ¶æ€: ${result.RecognitionStatus}`);
    }

    console.log("\n========== å®Œæ•´è¿”å› ==========");
    console.log(JSON.stringify(result, null, 2));

    console.log("\nâœ… æµ‹è¯•å®Œæˆï¼");
}

main().catch((err) => {
    console.error(`\nâŒ æµ‹è¯•å¤±è´¥: ${err.message}`);
    process.exit(1);
});
